{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully written to /nobackup/archive/grp/fslg_census/projects/paris_french_census/name_generation_joenelson/vocabs/family_names_no_spaces.json\n",
      "{'vocabulary': ['Martin', 'Bernard', 'Dubois', 'Thomas', 'Robert', 'Richard', 'Petit', 'Durand', 'Leroy', 'Moreau', 'Simon', 'Laurent', 'Michel', 'David', 'Morel', 'Roux', 'Fournier', 'Girard', 'Lambert', 'Mercier', 'Blanc', 'Lefebvre', 'Dupont', 'Faure', 'Bertrand', 'Morin', 'Garnier', 'Nicolas', 'Marie', 'Rousseau', 'Bonnet', 'Vincent', 'Henry', 'Masson', 'Robin', 'Martinez', 'Boyer', 'Muller', 'Denis', 'Chevalier', 'Lemaire', 'Meyer', 'Blanchard', 'Dufour', 'Vidal', 'Gauthier', 'Fontaine', 'Perrin', 'Joly', 'Jean', 'Gautier', 'Roche', 'Mathieu', 'Pereira', 'Roussel', 'Guerin', 'Duval', 'Aubert', 'Roy', 'Lefevre', 'Marchand', 'Picard', 'Caron', 'Gaillard', 'Louis', 'Meunier', 'Lucas', 'Dumont', 'Clement', 'Brunet', 'Giraud', 'Arnaud', 'Brun', 'Barbier', 'Rolland', 'Charles', 'Hubert', 'Moulin', 'Fabre', 'Guillaume', 'Dupuis', 'Leroux', 'Roger', 'Paris', 'Guillot', 'Dupuy', 'Carpentier', 'Payet', 'Antoine', 'Dumas', 'Paul', 'Jacques', 'Philippe', 'Olivier', 'Deschamps', 'Ferreira', 'Lacroix', 'Klein', 'Jacquet', 'Baron', 'Albert', 'Alves', 'Andre', 'Aubry', 'Bailly', 'Barre', 'Beaulieu', 'Beaumont', 'Benoit', 'Berthelot', 'Bertin', 'Besson', 'Boucher', 'Bouchet', 'Bourgeois', 'Camus', 'Charpentier', 'Chevallier', 'Dumouchel', 'Etienne', 'Ferrand', 'Fischer', 'Fleury', 'Francois', 'Gerard', 'Germain', 'Gilbert', 'Gillet', 'Guyot', 'Hamon', 'Hardy', 'Jacob', 'Julien', 'Lamy', 'Langlois', 'Laporte', 'Laval', 'Leblanc', 'Lebrun', 'Leclerc', 'Leclercq', 'Lecomte', 'Legrand', 'Lemoine', 'Levy', 'Maillard', 'Maillet', 'Marin', 'Marion', 'Martel', 'Marty', 'Michaud', 'Monnier', 'Noel', 'Ollivier', 'Paquet', 'Pelletier', 'Peltier', 'Pichon', 'Pierre', 'Poirier', 'Pons', 'Poulain', 'Raymond', 'Renard', 'Renaud', 'Renault', 'Rey', 'Royer', 'Salmon', 'Toussaint', 'Valentin', 'Vasseur', 'Arquette', 'Barbe', 'Bastien', 'Benard', 'Blondel', 'Bodin', 'Bonneau', 'Bonnin', 'Bourdon', 'Briand', 'Bruneau', 'Brunel', 'Carre', 'Charrier', 'Chauveau', 'Chauvet', 'Chauvin', 'Collet', 'Cordier', 'Cousin', 'Dior', 'Evrard', 'Faron', 'Favre', 'Foucher', 'Gilles', 'Guichard', 'Guillon', 'Lacoste', 'Lajoie', 'Lebon', 'Lebreton', 'Leduc', 'Lefort', 'Loiseau', 'Maillot', 'Mary', 'Maurice', 'Millet', 'Neveu', 'Perret', 'Pineau', 'Potier', 'Texier', 'Thibault', 'Vianney', 'Voisin', 'Alexandre', 'Aubin', 'Blaise', 'Boulanger', 'Camu', 'Coulon', 'Emery', 'Galopin', 'Georges', 'Gosselin', 'LaClair', 'Lagarde', 'Lanier', 'Larose', 'Larue', 'Launay', 'Leconte', 'Lesage', 'Louvet', 'Lyon', 'Marchal', 'Maret', 'Martineau', 'Maury', 'Merle', 'Pasquier', 'Perrier', 'Peyre', 'Raynaud', 'Remy', 'Reynaud', 'Robinette', 'Thierry', 'Tissier', 'Vaillant', 'Vallee', 'Amaury', 'Barbeau', 'Barthelemy', 'Beauchamp', 'Beauregard', 'Beauvais', 'Bellerose', 'Belleuse', 'Blanchet', 'Cartier', 'Chanel', 'Chartier', 'Christophe', 'Courtois', 'Couturier', 'Darrieux', 'Delacroix', 'Delaunay', 'Delmas', 'Delorme', 'Duhamel', 'Dupre', 'Gregoire', 'Imbert', 'Jourdan', 'Lacombe', 'Lafayette', 'Laroche', 'Lemaitre', 'Lemieux', 'Lenoir', 'Leveque', 'Magritte', 'Marais', 'Marnier', 'Marquet', 'Matisse', 'Monet', 'Montague', 'Riviere', 'Salomon', 'Thiebault', 'Valjean', 'Vallet', 'Verdier', 'Artois\\u200e', 'Bardot', 'Basquiat', 'Baudry', 'Bazin', 'Begue', 'Boutin', 'Bouvet', 'Bouvier', 'Carlier', 'Chambon', 'Coty', 'Coulomb', 'Cousteau', 'D’artagnan', 'Daumier', 'Delage', 'Dumoulin', 'Duvall', 'Fremont', 'Gabin', 'Gaudin', 'Grenier', 'Grondin', 'Herault', 'Herve', 'Hoarau', 'Hollier', 'Lecocq', 'Lejeune', 'Levasseur', 'Lombard', 'Loup', 'Mallet', 'Mercer', 'Morvan', 'Mouton', 'Pascal', 'Piaget', 'Preux', 'Prevost', 'Riou', 'Rodel', 'Rousseaux', 'Sauvage', 'Savoie', 'Tanguy', 'Theroux', 'Valette', 'Augustin', 'Bauge', 'Bigot', 'Blot', 'Bousquet', 'Burel', 'Cochin', 'Dabney', 'Derain', 'Devaux', 'Faivre', 'Fouquet', 'Gallet', 'Godard', 'Godin', 'Guyon', 'Herisson', 'Hoareau', 'Husson', 'Ignace', 'Joubert', 'Lecuyer', 'Milhaud', 'Montandon', 'Perrault', 'Pichard', 'Poncelet', 'Pruvost', 'Ribeiro', 'Rosamel', 'Seguin', 'Veron', 'Vial', 'Vianey', 'Vigee', 'Allaire', 'Auger', 'Autry', 'Baptiste', 'Bechet', 'Belon', 'Besnard', 'Bougie', 'Breton', 'Buisson', 'Chapin', 'Colas', 'Colbert', 'Collin', 'Coste', 'Tessier', 'Delancey', 'Delattre', 'Descamps', 'Descartes', 'Devereaux', 'Didier', 'Dionne', 'Dupond', 'Durant', 'Feret', 'Forest', 'Foret', 'Gervaise', 'Guibert', 'Guilbert', 'Guillet', 'Guillou', 'Hebert', 'Huet', 'Huguet', 'Humbert', 'Jacquot', 'Jourdain', 'Laliberte', 'Lozier', 'Maire', 'Masse', 'Maurin', 'Menard', 'Normand', 'Pernet', 'Perrot', 'Pottier', 'Rocher', 'Romilly', 'Rousset', 'Auguste', 'Beauden', 'Beaufort', 'Chastain', 'Clemence', 'Coutier', 'Couture', 'Croix', 'Devereau', 'Givenchy', 'Lafontaine', 'Lapointe', 'Lauren', 'Lavigne', 'Laviolette', 'Lecroix', 'Margaux', 'Marquess', 'Montagne', 'Pierrepont', 'Troix', 'Trudeau', 'Vernier', 'Vuitton', 'Yves', 'Ardennes\\u200e', 'Boufflers\\u200e', 'Bressieux\\u200e', 'Conde', 'D’Este', 'Fiennes', 'Lascaris\\u200e', 'Lascelles', 'Maille\\u200e', 'Potier\\u200e', 'Proude', 'Prouvost\\u200e', 'Roussillon', 'Sable\\u200e', 'Vermandois\\u200e', 'Vernier\\u200e', 'Villeneuve', 'Aragon', 'Battencourt\\u200e', 'Beauvilliers\\u200e', 'Boleyn', 'Bourbon\\u200e', 'Bourchier', 'Bullion', 'Burgundy', 'Cadieux', 'Charteris', 'Chopin', 'Conti', 'Courtenay\\u200e', 'Descartes\\u200e', 'Flanders', 'Givenchy\\u200e', 'LaSalle', 'Montfort\\u200e', 'Montmorency\\u200e', 'Normandy', 'Rivoli', 'Rothschild', 'Toulouse\\u200e', 'Villiers', 'Lefevre', 'Andre', 'Francois', 'Garcia', 'Clement', 'Noel', 'Riviere', 'Gerard', 'Schmitt', 'Colin', 'Benoit', '-', '-', '-', '-', '-', '-']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "# Function to remove accents\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "# Function to check if a name contains a space\n",
    "def has_space(name):\n",
    "    return ' ' in name\n",
    "\n",
    "try:\n",
    "    # Load your JSON file\n",
    "    with open('vocabs/family_names_no_spaces.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Verify the structure of the data\n",
    "    if 'vocabulary' not in data or not isinstance(data['vocabulary'], list):\n",
    "        raise ValueError(\"The JSON file does not contain a 'vocabulary' key with a list.\")\n",
    "\n",
    "    # Remove names with spaces\n",
    "    filtered_vocabulary = [\n",
    "        remove_accents(name) for name in data['vocabulary'] if not has_space(name)\n",
    "    ]\n",
    "\n",
    "    # Update the vocabulary in the data\n",
    "    data['vocabulary'] = filtered_vocabulary\n",
    "\n",
    "    # Write back to a new JSON file\n",
    "    output_path = 'vocabs/family_names_no_spaces.json'\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"File successfully written to {os.path.abspath(output_path)}\")\n",
    "    print(data)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All characters are English a-z.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "\n",
    "# Your input list\n",
    "with open('vocabs/family_names_no_spaces.json', 'r', encoding='utf-8') as f:\n",
    "    names = json.load(f)['vocabulary']\n",
    "\n",
    "# Define allowed characters (English a-z, A-Z)\n",
    "allowed_chars = set(string.ascii_letters)  # Includes both uppercase and lowercase English letters\n",
    "\n",
    "# Find characters that are not allowed\n",
    "non_english_chars = set()\n",
    "for name in names:\n",
    "    for char in name:\n",
    "        if char not in allowed_chars:\n",
    "            non_english_chars.add(char)\n",
    "\n",
    "# Print results\n",
    "if non_english_chars:\n",
    "    print(\"Non-English characters found:\", non_english_chars)\n",
    "else:\n",
    "    print(\"All characters are English a-z.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
